{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confidence\n",
    "\n",
    "> Estimating confidence that the suggested probabilities are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "## Google Colab / Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import enchant\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from fastai.text.all import *\n",
    "from pseudometer.data import *\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.newscientist.com/ link   28/  33 | https://www.facebook.com/newscientist = Rejected                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "d_dl = process_data(path, train_sources, k, min_words, max_words, ignore_text, ignore_common, \n",
    "            ignore_filenames, max_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sci = []\n",
    "train_pse = []\n",
    "test_sci = []\n",
    "test_pse = []\n",
    "for link in d_dl:\n",
    "    text = d_dl[link][0]\n",
    "    cat = d_dl[link][2]\n",
    "    r = random.randint(0,5)\n",
    "    if cat == 'science' and r != 0:\n",
    "        train_sci.append(text)\n",
    "    elif cat == 'science' and r == 0:\n",
    "        test_sci.append(text)\n",
    "    elif cat == 'pseudoscience' and r != 0:\n",
    "        train_pse.append(text)\n",
    "    elif cat == 'pseudoscience' and r == 0:\n",
    "        test_pse.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    norm = []\n",
    "    for val in arr:\n",
    "        norm.append((val-np.min(arr))/(np.max(arr)-np.min(arr)))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science, science': [0.44, 0.5],\n",
       " 'science, pseudoscience': [0.27, 0.44],\n",
       " 'pseudoscience, science': [0.47, 0.5],\n",
       " 'pseudoscience, pseudoscience': [0.63, 0.48]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sets = {'science':train_sci, 'pseudoscience':train_pse}\n",
    "test_sets = {'science':test_sci, 'pseudoscience':test_pse}\n",
    "norms = {}\n",
    "vectorizer = TfidfVectorizer()\n",
    "for cat_train in train_sets:\n",
    "    for cat_test in test_sets:\n",
    "        train_set = train_sets[cat_train]\n",
    "        test_set = test_sets[cat_test]\n",
    "        train_vectors = vectorizer.fit_transform(train_set)\n",
    "        test_vectors = vectorizer.transform(test_set)\n",
    "\n",
    "        model = OneClassSVM(gamma='auto')\n",
    "        model.fit(train_vectors)\n",
    "\n",
    "        test_predictions = model.predict(test_vectors)\n",
    "        norm = normalize(test_predictions)\n",
    "        norms[cat_train+', '+cat_test] = [np.round(np.mean(norm),2),np.round(np.std(norm),2)]\n",
    "\n",
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = load_learner('models/2022.11.28 Model.pth', cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
