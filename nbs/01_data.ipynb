{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Web scraping and tools for data collection and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import enchant\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Function to Check GPU Status\n",
    "def check_gpu():\n",
    "    print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    if num_devices > 0:\n",
    "        for device in range(0,num_devices):\n",
    "            print(\"Device\", device, \"|\", torch.cuda.get_device_name(device), \n",
    "            \"| Allocated:\", round(torch.cuda.memory_allocated(device)/1024**3,1), \"GB\",\n",
    "            \"| Cached:\", round(torch.cuda.memory_reserved(device)/1024**3,1), \"GB\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Device 0 | NVIDIA GeForce RTX 3050 Ti Laptop GPU | Allocated: 0.0 GB | Cached: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Webpage:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.html = \"\"\n",
    "        self.links = []\n",
    "        self.text = []\n",
    "        self.cleaned_text = []\n",
    "        self.most_common_words = []\n",
    "\n",
    "    def get_html(self, timeout = 5):\n",
    "        user_agents = [ \n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', \n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36', \n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36', \n",
    "            'Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148', \n",
    "            'Mozilla/5.0 (Linux; Android 11; SM-G960U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Mobile Safari/537.36' \n",
    "        ] \n",
    "        user_agent = random.choice(user_agents) \n",
    "        headers = {'User-Agent': user_agent} \n",
    "        page = requests.get(self.url, timeout=timeout, headers=headers)\n",
    "        self.html = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    def get_html_anchors(self, keyword=\"http\"):\n",
    "        for anchor in self.html.findAll('a'):\n",
    "            link = anchor.get('href')\n",
    "            if link == None or link == \"\":\n",
    "                continue\n",
    "            if keyword in link:\n",
    "                self.links.append(link)\n",
    "                \n",
    "    def get_html_text(self, tags=[\"p\"]):\n",
    "        for tag in tags:\n",
    "            for p in self.html.findAll(tag):\n",
    "                p_text = p.getText().strip()\n",
    "                if p_text == None or p_text == '':\n",
    "                    continue\n",
    "                self.text.append(p_text)\n",
    "\n",
    "    def clean_text(self, enchant_dict=\"en_US\"):\n",
    "        rx = \"[^a-zA-Z0-9 ]+\"\n",
    "        all_text = ' '.join(self.text)\n",
    "        regex_text = re.sub(rx,'',all_text).strip()\n",
    "        split = regex_text.split()\n",
    "        if enchant_dict != \"\": d = enchant.Dict(enchant_dict)\n",
    "        for word in split:\n",
    "            if enchant_dict == \"\":\n",
    "                self.cleaned_text.append(word)\n",
    "            elif d.check(word): \n",
    "                self.cleaned_text.append(word)\n",
    "\n",
    "    def k_common_words(self, k=10, ignore=[\"the\",\"to\",\"of\",\"and\",\"a\",\"in\",\"on\",\"is\",\"for\",\"by\"]):\n",
    "        if self.cleaned_text == \"\":\n",
    "            text = self.text\n",
    "        else:\n",
    "            text = self.cleaned_text\n",
    "        all_text = ' '.join(text).lower()\n",
    "        split = all_text.split()\n",
    "        split_ignore = [word for word in split if word not in ignore]\n",
    "        counts = Counter(split_ignore)\n",
    "        k_most_common = counts.most_common(k)\n",
    "        self.most_common_words = k_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 most common English words\n"
     ]
    }
   ],
   "source": [
    "url = \"https://gist.githubusercontent.com/deekayen/4148741/raw/98d35708fa344717d8eee15d11987de6c8e26d7d/1-1000.txt\"\n",
    "common_english = Webpage(url)\n",
    "common_english.get_html()\n",
    "english_words = common_english.html.getText().lower()\n",
    "english_words = english_words.split('\\n')\n",
    "print(len(english_words),\"most common English words\")\n",
    "#english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_sources = [\"http://www.ageofautism.com/\",\n",
    " \"http://www.naturalnews.com\", \n",
    " \"https://foodbabe.com/starthere/\",\n",
    " \"http://www.chopra.com\",\n",
    " \"https://www.mercola.com/\",\n",
    " \"https://www.history.com/\",\n",
    " \"https://doctoroz.com/\",\n",
    " \"https://www.disclose.tv/\",\n",
    " \"https://christiananswers.net/\",\n",
    " \"https://heartland.org/\"]\n",
    "\n",
    "science_sources = [\"https://sciencebasedmedicine.org/\",\n",
    " \"https://www.hopkinsmedicine.org/gim/research/method/ebm.html\",\n",
    " \"https://www.bbc.com/news/science_and_environment\",\n",
    " \"https://www.nature.com/\",\n",
    " \"https://www.science.org/\",\n",
    " \"https://www.snopes.com/top/\",\n",
    " \"https://quackwatch.org/\",\n",
    " \"https://www.skepdic.com/\",\n",
    " \"http://scibabe.com/\",\n",
    " \"http://pandasthumb.org/\",\n",
    " \"https://skepticalscience.com/\",\n",
    " \"https://www.cdc.gov/vaccinesafety/concerns/autism.html\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'Holland',\n",
       " 'Polly',\n",
       " 'host',\n",
       " 'a',\n",
       " 'program',\n",
       " 'on',\n",
       " 'TV',\n",
       " 'also',\n",
       " 'available',\n",
       " 'as',\n",
       " 'audio',\n",
       " 'on',\n",
       " 'You',\n",
       " 'can',\n",
       " 'find',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'programming',\n",
       " 'on',\n",
       " 'TV',\n",
       " 'HERE',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Week',\n",
       " 'with',\n",
       " 'Mary',\n",
       " 'Holland',\n",
       " 'Health',\n",
       " 'Defense',\n",
       " 'president',\n",
       " 'and',\n",
       " 'Polly',\n",
       " 'programming',\n",
       " 'manager',\n",
       " 'Mary',\n",
       " 'and',\n",
       " 'Polly',\n",
       " 'discuss',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'news',\n",
       " 'on',\n",
       " 'vaccines',\n",
       " 'and',\n",
       " 'other',\n",
       " 'issues',\n",
       " 'Click',\n",
       " 'HERE',\n",
       " 'This',\n",
       " 'week',\n",
       " 'Mary',\n",
       " 'Holland',\n",
       " 'Health',\n",
       " 'Defense',\n",
       " 'president',\n",
       " 'and',\n",
       " 'Polly',\n",
       " 'programming',\n",
       " 'manager',\n",
       " 'covered',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'headlines',\n",
       " 'on',\n",
       " 'Big',\n",
       " 'and',\n",
       " 'other',\n",
       " 'issues',\n",
       " 'including',\n",
       " 'news',\n",
       " 'that',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'signaled',\n",
       " 'its',\n",
       " 'time',\n",
       " 'to',\n",
       " 'move',\n",
       " 'on',\n",
       " 'from',\n",
       " 'the',\n",
       " 'pandemic',\n",
       " 'with',\n",
       " 'a',\n",
       " 'bipartisan',\n",
       " '6236',\n",
       " 'to',\n",
       " 'end',\n",
       " 'the',\n",
       " 'federal',\n",
       " 'governments',\n",
       " 'emergency',\n",
       " 'declaration',\n",
       " 'on',\n",
       " 'the',\n",
       " 'pandemic',\n",
       " 'Polly',\n",
       " 'and',\n",
       " 'Mary',\n",
       " 'also',\n",
       " 'discussed',\n",
       " 'that',\n",
       " 'NBC',\n",
       " 'is',\n",
       " 'pushing',\n",
       " 'the',\n",
       " 'claiming',\n",
       " 'that',\n",
       " 'children',\n",
       " 'are',\n",
       " 'at',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'during',\n",
       " 'the',\n",
       " 'holiday',\n",
       " 'season',\n",
       " 'Plus',\n",
       " 'the',\n",
       " 'Biden',\n",
       " 'administration',\n",
       " 'is',\n",
       " 'offering',\n",
       " 'discounts',\n",
       " 'on',\n",
       " 'groceries',\n",
       " 'to',\n",
       " 'Americans',\n",
       " 'who',\n",
       " 'get',\n",
       " 'the',\n",
       " 'new',\n",
       " 'bivalent',\n",
       " 'booster',\n",
       " 'in',\n",
       " 'a',\n",
       " 'desperate',\n",
       " 'bid',\n",
       " 'to',\n",
       " 'boost',\n",
       " 'uptake',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'Also',\n",
       " 'on',\n",
       " 'tap',\n",
       " 'this',\n",
       " 'week',\n",
       " 'Pfizer',\n",
       " 'and',\n",
       " 'are',\n",
       " 'launching',\n",
       " 'clinical',\n",
       " 'trials',\n",
       " 'to',\n",
       " 'track',\n",
       " 'health',\n",
       " 'issues',\n",
       " 'following',\n",
       " 'a',\n",
       " 'diagnosis',\n",
       " 'of',\n",
       " 'and',\n",
       " 'pericarditis',\n",
       " 'in',\n",
       " 'teens',\n",
       " 'and',\n",
       " 'young',\n",
       " 'adults',\n",
       " 'but',\n",
       " 'some',\n",
       " 'experts',\n",
       " 'said',\n",
       " 'the',\n",
       " 'risks',\n",
       " 'are',\n",
       " 'already',\n",
       " 'clear',\n",
       " 'Support',\n",
       " 'this',\n",
       " 'holiday',\n",
       " 'season',\n",
       " 'on',\n",
       " 'this',\n",
       " 'limited',\n",
       " 'edition',\n",
       " 'box',\n",
       " 'set',\n",
       " 'signed',\n",
       " 'by',\n",
       " 'Robert',\n",
       " 'Kennedy',\n",
       " 'Jr',\n",
       " 'Posted',\n",
       " 'by',\n",
       " 'Age',\n",
       " 'of',\n",
       " 'Autism',\n",
       " 'on',\n",
       " 'November',\n",
       " '28',\n",
       " '2022',\n",
       " 'at',\n",
       " '0601',\n",
       " 'AM',\n",
       " 'in',\n",
       " 'Current',\n",
       " 'Affairs',\n",
       " 'Comments',\n",
       " '1',\n",
       " 'Beautiful',\n",
       " 'talented',\n",
       " 'and',\n",
       " '63',\n",
       " 'year',\n",
       " 'young',\n",
       " 'Irene',\n",
       " 'Cara',\n",
       " 'died',\n",
       " 'a',\n",
       " 'sudden',\n",
       " 'death',\n",
       " 'over',\n",
       " 'the',\n",
       " 'holiday',\n",
       " 'Social',\n",
       " 'media',\n",
       " 'was',\n",
       " 'full',\n",
       " 'of',\n",
       " 'women',\n",
       " 'of',\n",
       " 'a',\n",
       " 'certain',\n",
       " 'age',\n",
       " 'sharing',\n",
       " 'their',\n",
       " 'grief',\n",
       " 'at',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'Other',\n",
       " 'women',\n",
       " 'of',\n",
       " 'a',\n",
       " 'certain',\n",
       " 'age',\n",
       " 'points',\n",
       " 'at',\n",
       " 'self',\n",
       " 'were',\n",
       " 'asking',\n",
       " 'questions',\n",
       " 'Was',\n",
       " 'Ms',\n",
       " 'Cara',\n",
       " 'another',\n",
       " 'Died',\n",
       " 'Suddenly',\n",
       " 'Cause',\n",
       " 'Unknown',\n",
       " 'Seems',\n",
       " 'folks',\n",
       " 'started',\n",
       " 'asking',\n",
       " 'the',\n",
       " 'Cara',\n",
       " 'Twitter',\n",
       " 'account',\n",
       " 'if',\n",
       " 'perhaps',\n",
       " 'she',\n",
       " 'had',\n",
       " 'been',\n",
       " 'vaccinated',\n",
       " 'for',\n",
       " 'and',\n",
       " 'could',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'have',\n",
       " 'played',\n",
       " 'a',\n",
       " 'role',\n",
       " 'in',\n",
       " 'her',\n",
       " 'death',\n",
       " 'And',\n",
       " 'the',\n",
       " 'the',\n",
       " 'publicist',\n",
       " 'who',\n",
       " 'runs',\n",
       " 'her',\n",
       " 'account',\n",
       " 'asked',\n",
       " 'that',\n",
       " 'the',\n",
       " 'questions',\n",
       " 'STOP',\n",
       " 'One',\n",
       " 'would',\n",
       " 'hope',\n",
       " 'that',\n",
       " 'people',\n",
       " 'were',\n",
       " 'asking',\n",
       " 'as',\n",
       " 'gently',\n",
       " 'as',\n",
       " 'possible',\n",
       " 'without',\n",
       " 'the',\n",
       " 'glee',\n",
       " 'or',\n",
       " 'malice',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'the',\n",
       " 'vaccinated',\n",
       " 'when',\n",
       " 'an',\n",
       " 'person',\n",
       " 'would',\n",
       " 'get',\n",
       " 'Cara',\n",
       " 'herself',\n",
       " 'answered',\n",
       " 'the',\n",
       " 'question',\n",
       " 'of',\n",
       " 'uptake',\n",
       " 'on',\n",
       " 'March',\n",
       " 'of',\n",
       " '2021',\n",
       " 'Perhaps',\n",
       " 'autopsy',\n",
       " 'results',\n",
       " 'will',\n",
       " 'show',\n",
       " 'something',\n",
       " 'completely',\n",
       " 'unrelated',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'Newcomers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'injury',\n",
       " 'topic',\n",
       " 'those',\n",
       " 'who',\n",
       " 'did',\n",
       " 'NOT',\n",
       " 'acknowledge',\n",
       " 'the',\n",
       " 'injuries',\n",
       " 'written',\n",
       " 'about',\n",
       " 'for',\n",
       " '15',\n",
       " 'years',\n",
       " 'will',\n",
       " 'be',\n",
       " 'shocked',\n",
       " 'when',\n",
       " 'they',\n",
       " 'are',\n",
       " 'shut',\n",
       " 'down',\n",
       " 'from',\n",
       " 'asking',\n",
       " 'the',\n",
       " 'question',\n",
       " 'Its',\n",
       " 'almost',\n",
       " 'cute',\n",
       " 'Aw',\n",
       " 'surprised',\n",
       " 'Us',\n",
       " 'Please',\n",
       " 'known',\n",
       " 'that',\n",
       " 'anything',\n",
       " 'that',\n",
       " 'befalls',\n",
       " 'a',\n",
       " 'child',\n",
       " 'or',\n",
       " 'an',\n",
       " 'adult',\n",
       " 'as',\n",
       " 'long',\n",
       " 'it',\n",
       " 'came',\n",
       " 'from',\n",
       " 'a',\n",
       " 'vaccine',\n",
       " 'no',\n",
       " 'matter',\n",
       " 'how',\n",
       " 'disabling',\n",
       " 'or',\n",
       " 'murderous',\n",
       " 'it',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'discussed',\n",
       " 'In',\n",
       " '2022',\n",
       " 'suicide',\n",
       " 'drug',\n",
       " 'overdose',\n",
       " 'and',\n",
       " 'even',\n",
       " 'car',\n",
       " 'accidents',\n",
       " 'that',\n",
       " 'harm',\n",
       " 'others',\n",
       " 'Ms',\n",
       " 'are',\n",
       " 'preferable',\n",
       " 'and',\n",
       " 'even',\n",
       " 'honorable',\n",
       " 'deaths',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heretical',\n",
       " 'theoretical',\n",
       " 'vaccine',\n",
       " 'induced',\n",
       " 'git',\n",
       " 'along',\n",
       " 'little',\n",
       " 'doggies',\n",
       " 'ask',\n",
       " 'In',\n",
       " 'the',\n",
       " 'meantime',\n",
       " 'I',\n",
       " 'suggest',\n",
       " 'we',\n",
       " 'each',\n",
       " 'send',\n",
       " 'a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'Cause',\n",
       " 'Unknown',\n",
       " 'The',\n",
       " 'Epidemic',\n",
       " 'of',\n",
       " 'Sudden',\n",
       " 'Deaths',\n",
       " 'in',\n",
       " '2020',\n",
       " 'and',\n",
       " '2021',\n",
       " 'by',\n",
       " 'Ed',\n",
       " 'to',\n",
       " 'every',\n",
       " 'publicist',\n",
       " 'in',\n",
       " 'the',\n",
       " 'USA',\n",
       " 'Posted',\n",
       " 'by',\n",
       " 'Age',\n",
       " 'of',\n",
       " 'Autism',\n",
       " 'on',\n",
       " 'November',\n",
       " '28',\n",
       " '2022',\n",
       " 'at',\n",
       " '0600',\n",
       " 'AM',\n",
       " 'in',\n",
       " 'Vaccine',\n",
       " 'Safety',\n",
       " 'Comments',\n",
       " '0',\n",
       " 'By',\n",
       " 'Cathy',\n",
       " 'On',\n",
       " 'weekends',\n",
       " 'my',\n",
       " 'husband',\n",
       " 'and',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'routine',\n",
       " 'whoever',\n",
       " 'wakes',\n",
       " 'up',\n",
       " 'first',\n",
       " 'gets',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'the',\n",
       " 'day',\n",
       " 'That',\n",
       " 'means',\n",
       " 'taking',\n",
       " 'him',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " 'getting',\n",
       " 'him',\n",
       " 'changed',\n",
       " 'and',\n",
       " 'giving',\n",
       " 'him',\n",
       " 'his',\n",
       " 'While',\n",
       " 'one',\n",
       " 'of',\n",
       " 'us',\n",
       " 'tends',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'gets',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'a',\n",
       " 'break',\n",
       " 'to',\n",
       " 'ease',\n",
       " 'into',\n",
       " 'the',\n",
       " 'day',\n",
       " 'Its',\n",
       " 'a',\n",
       " 'sweet',\n",
       " 'relationship',\n",
       " 'my',\n",
       " 'husband',\n",
       " 'and',\n",
       " 'have',\n",
       " 'Father',\n",
       " 'dotes',\n",
       " 'on',\n",
       " 'son',\n",
       " 'Son',\n",
       " 'looks',\n",
       " 'up',\n",
       " 'to',\n",
       " 'father',\n",
       " 'They',\n",
       " 'need',\n",
       " 'me',\n",
       " 'to',\n",
       " 'intervene',\n",
       " 'or',\n",
       " 'butt',\n",
       " 'in',\n",
       " 'the',\n",
       " 'way',\n",
       " 'of',\n",
       " 'their',\n",
       " 'weekend',\n",
       " 'routine',\n",
       " 'One',\n",
       " 'recent',\n",
       " 'morning',\n",
       " 'though',\n",
       " 'when',\n",
       " 'I',\n",
       " 'got',\n",
       " 'up',\n",
       " 'later',\n",
       " 'than',\n",
       " 'my',\n",
       " 'fellas',\n",
       " 'I',\n",
       " 'heard',\n",
       " 'take',\n",
       " 'his',\n",
       " 'Sausage',\n",
       " 'eggs',\n",
       " 'a',\n",
       " 'waffle',\n",
       " 'and',\n",
       " 'a',\n",
       " 'cup',\n",
       " 'of',\n",
       " 'coffee',\n",
       " 'its',\n",
       " 'a',\n",
       " 'breakfast',\n",
       " 'I',\n",
       " 'make',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'day',\n",
       " 'gets',\n",
       " 'the',\n",
       " 'same',\n",
       " 'sans',\n",
       " 'the',\n",
       " 'coffee',\n",
       " 'been',\n",
       " 'awake',\n",
       " 'for',\n",
       " 'about',\n",
       " '15',\n",
       " 'minutes',\n",
       " 'by',\n",
       " 'the',\n",
       " 'time',\n",
       " 'Id',\n",
       " 'gotten',\n",
       " 'our',\n",
       " 'meals',\n",
       " 'ready',\n",
       " 'last',\n",
       " 'Sunday',\n",
       " 'morning',\n",
       " 'Assuming',\n",
       " 'my',\n",
       " 'husband',\n",
       " 'had',\n",
       " 'already',\n",
       " 'gotten',\n",
       " 'his',\n",
       " 'morning',\n",
       " 'I',\n",
       " 'hovered',\n",
       " 'over',\n",
       " 'my',\n",
       " 'chair',\n",
       " 'just',\n",
       " 'about',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'down',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'I',\n",
       " 'gotten',\n",
       " 'a',\n",
       " 'good',\n",
       " 'night',\n",
       " 'of',\n",
       " 'sleep',\n",
       " 'the',\n",
       " 'night',\n",
       " 'before',\n",
       " 'and',\n",
       " 'was',\n",
       " 'less',\n",
       " 'than',\n",
       " 'chipper',\n",
       " 'that',\n",
       " 'morning',\n",
       " 'So',\n",
       " 'I',\n",
       " 'blurted',\n",
       " 'out',\n",
       " 'I',\n",
       " 'assume',\n",
       " 'hes',\n",
       " 'just',\n",
       " 'waiting',\n",
       " 'for',\n",
       " 'his',\n",
       " 'meal',\n",
       " 'right',\n",
       " 'My',\n",
       " 'husband',\n",
       " 'apologized',\n",
       " 'and',\n",
       " 'said',\n",
       " 'No',\n",
       " 'he',\n",
       " 'still',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'take',\n",
       " 'the',\n",
       " 'Grumbling',\n",
       " 'I',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'and',\n",
       " 'then',\n",
       " 'stood',\n",
       " 'back',\n",
       " 'up',\n",
       " 'saying',\n",
       " 'Ill',\n",
       " 'do',\n",
       " 'it',\n",
       " 'Looking',\n",
       " 'at',\n",
       " 'me',\n",
       " 'shocked',\n",
       " 'it',\n",
       " 'was',\n",
       " 'my',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'apologize',\n",
       " 'sorry',\n",
       " 'just',\n",
       " 'really',\n",
       " 'hungry',\n",
       " 'I',\n",
       " 'can',\n",
       " 'do',\n",
       " 'it',\n",
       " 'Feeling',\n",
       " 'frustrated',\n",
       " 'and',\n",
       " 'embarrassed',\n",
       " 'that',\n",
       " 'Id',\n",
       " 'been',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'put',\n",
       " 'off',\n",
       " 'I',\n",
       " 'got',\n",
       " 'what',\n",
       " 'he',\n",
       " 'needed',\n",
       " 'Since',\n",
       " 'we',\n",
       " 'have',\n",
       " 'to',\n",
       " 'feed',\n",
       " 'him',\n",
       " 'his',\n",
       " 'breakfast',\n",
       " 'which',\n",
       " 'can',\n",
       " 'take',\n",
       " 'about',\n",
       " '20',\n",
       " 'minutes',\n",
       " 'to',\n",
       " 'do',\n",
       " 'I',\n",
       " 'quickly',\n",
       " 'gobbled',\n",
       " 'up',\n",
       " 'mine',\n",
       " 'first',\n",
       " 'It',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'a',\n",
       " 'selfish',\n",
       " 'move',\n",
       " 'in',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'but',\n",
       " 'on',\n",
       " 'days',\n",
       " 'that',\n",
       " 'start',\n",
       " 'off',\n",
       " 'on',\n",
       " 'the',\n",
       " 'wrong',\n",
       " 'foot',\n",
       " 'like',\n",
       " 'that',\n",
       " 'day',\n",
       " 'had',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'best',\n",
       " 'to',\n",
       " 'try',\n",
       " 'to',\n",
       " 'take',\n",
       " 'care',\n",
       " 'of',\n",
       " 'me',\n",
       " 'before',\n",
       " 'I',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'take',\n",
       " 'care',\n",
       " 'of',\n",
       " 'or',\n",
       " 'the',\n",
       " 'other',\n",
       " 'people',\n",
       " 'in',\n",
       " 'my',\n",
       " 'life',\n",
       " 'takes',\n",
       " 'up',\n",
       " 'the',\n",
       " 'most',\n",
       " 'of',\n",
       " 'my',\n",
       " 'attention',\n",
       " 'He',\n",
       " 'always',\n",
       " 'has',\n",
       " 'Continue',\n",
       " 'reading',\n",
       " 'Flooded',\n",
       " 'With',\n",
       " 'Emotion',\n",
       " 'Posted',\n",
       " 'by',\n",
       " 'Age',\n",
       " 'of',\n",
       " 'Autism',\n",
       " 'on',\n",
       " 'November',\n",
       " '27',\n",
       " '2022',\n",
       " 'at',\n",
       " '0600',\n",
       " 'AM',\n",
       " 'in',\n",
       " 'Cathy',\n",
       " 'Comments',\n",
       " '9',\n",
       " 'Were',\n",
       " 'so',\n",
       " 'close',\n",
       " 'to',\n",
       " 'meeting',\n",
       " 'our',\n",
       " 'goal',\n",
       " 'Can',\n",
       " 'you',\n",
       " 'nudge',\n",
       " 'us',\n",
       " 'over',\n",
       " 'We',\n",
       " 'have',\n",
       " 'an',\n",
       " 'angel',\n",
       " 'donor',\n",
       " 'in',\n",
       " 'Laura',\n",
       " 'Hayes',\n",
       " 'contributor',\n",
       " 'and',\n",
       " 'supporter',\n",
       " 'who',\n",
       " 'has',\n",
       " 'generously',\n",
       " 'upped',\n",
       " 'her',\n",
       " 'annual',\n",
       " 'match',\n",
       " 'to',\n",
       " 'a',\n",
       " 'full',\n",
       " '10000',\n",
       " 'Meeting',\n",
       " 'this',\n",
       " 'campaign',\n",
       " 'would',\n",
       " 'be',\n",
       " 'heaven',\n",
       " 'for',\n",
       " 'us',\n",
       " 'Were',\n",
       " 'at',\n",
       " '75',\n",
       " 'of',\n",
       " 'our',\n",
       " 'goal',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'Every',\n",
       " 'penny',\n",
       " 'keeps',\n",
       " 'work',\n",
       " 'is',\n",
       " 'more',\n",
       " 'important',\n",
       " 'than',\n",
       " 'ever',\n",
       " 'as',\n",
       " 'families',\n",
       " 'smash',\n",
       " 'into',\n",
       " 'and',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'grind',\n",
       " 'out',\n",
       " 'the',\n",
       " 'challenges',\n",
       " 'that',\n",
       " 'autism',\n",
       " 'brings',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'lifespan',\n",
       " 'The',\n",
       " 'cute',\n",
       " 'girls',\n",
       " 'I',\n",
       " 'used',\n",
       " 'to',\n",
       " 'write',\n",
       " 'about',\n",
       " 'are',\n",
       " '22',\n",
       " '26',\n",
       " 'and',\n",
       " 'almost',\n",
       " '28',\n",
       " 'years',\n",
       " 'old',\n",
       " 'now',\n",
       " 'Once',\n",
       " 'school',\n",
       " 'ends',\n",
       " 'huge',\n",
       " 'new',\n",
       " 'hurdles',\n",
       " 'arise',\n",
       " 'Age',\n",
       " 'of',\n",
       " 'Autism',\n",
       " 'will',\n",
       " 'NOT',\n",
       " 'stop',\n",
       " 'telling',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'about',\n",
       " 'autism',\n",
       " 'I',\n",
       " 'need',\n",
       " 'your',\n",
       " 'help',\n",
       " 'in',\n",
       " 'this',\n",
       " 'our',\n",
       " '15th',\n",
       " 'year',\n",
       " 'We',\n",
       " 'use',\n",
       " 'for',\n",
       " 'secure',\n",
       " 'online',\n",
       " 'donations',\n",
       " 'and',\n",
       " 'you',\n",
       " 'can',\n",
       " 'always',\n",
       " 'send',\n",
       " 'a',\n",
       " 'check',\n",
       " 'to',\n",
       " 'Autism',\n",
       " 'Age',\n",
       " 'PO',\n",
       " 'Box',\n",
       " '110546',\n",
       " 'Trumbull',\n",
       " 'CT',\n",
       " '06611',\n",
       " 'Donations',\n",
       " 'are',\n",
       " 'tax',\n",
       " 'deductible',\n",
       " 'is',\n",
       " '471831987',\n",
       " 'Thanks',\n",
       " 'to',\n",
       " 'a',\n",
       " 'generous',\n",
       " 'gift',\n",
       " 'last',\n",
       " 'year',\n",
       " ...]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = pseudo_sources[0]\n",
    "test_page = Webpage(url)\n",
    "test_page.get_html()\n",
    "test_page.get_html_anchors()\n",
    "test_page.get_html_text(tags=[\"p\",\"h1\",\"h2\",\"h3\",\"span\"])\n",
    "test_page.clean_text()\n",
    "test_page.k_common_words(k=5,ignore=english_words[:30])\n",
    "test_page.most_common_words\n",
    "test_page.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_page_all(url, k, ignore_words):\n",
    "    page = Webpage(url)\n",
    "    page.get_html()\n",
    "    page.get_html_text(tags=[\"p\",\"h1\",\"h2\",\"h3\",\"span\"])\n",
    "    page.clean_text()\n",
    "    page.k_common_words(k=k, ignore=ignore_words)\n",
    "    page.get_html_anchors()\n",
    "    return page\n",
    "\n",
    "def get_all_links(url, dict, k, min_text_len=50, ignore_words=[], ignore_filenames=[\".mp3\",\".jpg\",\".png\"]):\n",
    "    page = get_page_all(url, k, ignore_words)\n",
    "    text = ' '.join(page.cleaned_text)\n",
    "    dict[url] = [text, page.most_common_words]\n",
    "    print(url,\"Contains\",len(page.links),\"Links\")\n",
    "\n",
    "    for link in page.links:\n",
    "        if all(x not in link for x in ignore_filenames):\n",
    "            try:\n",
    "                page = get_page_all(link, k, ignore_words)\n",
    "                text = ' '.join(page.cleaned_text)\n",
    "                if len(text) < min_text_len: continue\n",
    "                dict[link] = [text, page.most_common_words]\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30 # words\n",
    "min_text_len = 50\n",
    "max_text_len = 2000\n",
    "ignore_words = english_words[:50]\n",
    "ignore_filenames = [\".mp3\",\".jpg\",\".png\",\".mp4\",\"facebook.com\",\"twitter.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#d_pse = {}\n",
    "#get_all_links(pseudo_sources[2], d_pse, k, min_text_len, ignore_words, ignore_filenames)\n",
    "#d_pse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ageofautism.com/ Contains 697 Links\n",
      "http://www.naturalnews.com Contains 324 Links\n",
      "https://foodbabe.com/starthere/ Contains 122 Links\n",
      "http://www.chopra.com Contains 100 Links\n",
      "https://www.mercola.com/ Contains 125 Links\n",
      "https://www.history.com/ Contains 83 Links\n",
      "https://doctoroz.com/ Contains 133 Links\n",
      "https://www.disclose.tv/ Contains 140 Links\n",
      "https://christiananswers.net/ Contains 9 Links\n",
      "https://heartland.org/ Contains 142 Links\n",
      "https://sciencebasedmedicine.org/ Contains 259 Links\n",
      "https://www.hopkinsmedicine.org/gim/research/method/ebm.html Contains 103 Links\n",
      "https://www.bbc.com/news/science_and_environment Contains 131 Links\n",
      "https://www.nature.com/ Contains 73 Links\n",
      "https://www.science.org/ Contains 29 Links\n",
      "https://www.snopes.com/top/ Contains 35 Links\n",
      "https://quackwatch.org/ Contains 136 Links\n",
      "https://www.skepdic.com/ Contains 103 Links\n",
      "http://scibabe.com/ Contains 118 Links\n"
     ]
    }
   ],
   "source": [
    "d_pse = {}\n",
    "d_sci = {}\n",
    "\n",
    "for source in pseudo_sources:\n",
    "    get_all_links(source, d_pse, k, min_text_len, ignore_words, ignore_filenames)\n",
    "for source in science_sources:\n",
    "    get_all_links(source, d_sci, k, min_text_len, ignore_words, ignore_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Pseudoscience 30 Most Common Words ####\n",
      " [('autism', 6336), ('health', 5135), ('our', 4567), ('my', 3674), ('about', 3659), ('has', 3635), ('more', 3572), ('vaccine', 3460), ('will', 3387), ('posted', 3351), ('any', 3249), ('2022', 3161), ('their', 2922), ('age', 2921), ('food', 2888), ('its', 2730), ('am', 2683), ('us', 2216), ('who', 2211), ('if', 2135), ('so', 1947), ('news', 1915), ('no', 1731), ('may', 1660), ('been', 1652), ('these', 1628), ('children', 1614), ('information', 1590), ('like', 1566), ('natural', 1492)] \n",
      "\n",
      "\n",
      "#### Science 30 Most Common Words ####\n",
      " [('0', 28983), ('j', 3412), ('climate', 3092), ('n', 2979), ('2', 2643), ('m', 2593), ('r', 2519), ('more', 2282), ('00000', 2124), ('p', 2104), ('c', 2050), ('s', 1935), ('about', 1888), ('change', 1781), ('scholar', 1682), ('2022', 1659), ('science', 1655), ('d', 1624), ('medicine', 1607), ('global', 1591), ('our', 1450), ('g', 1443), ('3', 1424), ('612', 1410), ('l', 1332), ('data', 1303), ('t', 1299), ('emissions', 1283), ('google', 1256), ('2021', 1135)] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_pse = Counter()\n",
    "count_sci = Counter()\n",
    "for link in d_pse:\n",
    "    count_pse+=Counter(dict(d_pse[link][1]))\n",
    "for link in d_sci:\n",
    "    count_sci+=Counter(dict(d_sci[link][1]))\n",
    "\n",
    "print(\"#### Pseudoscience\",k,\"Most Common Words ####\\n\",count_pse.most_common(k),\"\\n\\n\")\n",
    "print(\"#### Science\",k,\"Most Common Words ####\\n\",count_sci.most_common(k),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>common_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://www.ageofautism.com/</th>\n",
       "      <td>host a program on also available as audio on you can find all of the programming on here in this week with health defense president and programming manager and discuss the latest news on vaccines and other issues click here this week health defense president and programming manager covered the latest headlines on big and other issues including news that the senate signaled its time to move on from the pandemic with a bipartisan 6236 to end the federal governments emergency declaration on the pandemic and also discussed that is pushing the claiming that children are at high risk during the ...</td>\n",
       "      <td>autism age vaccine 2022 am posted health our 0600 my about will its their comments us children current her affairs more who me been reading public defense new him continue</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.ageofautism.com/</th>\n",
       "      <td>host a program on also available as audio on you can find all of the programming on here in this week with health defense president and programming manager and discuss the latest news on vaccines and other issues click here this week health defense president and programming manager covered the latest headlines on big and other issues including news that the senate signaled its time to move on from the pandemic with a bipartisan 6236 to end the federal governments emergency declaration on the pandemic and also discussed that is pushing the claiming that children are at high risk during the ...</td>\n",
       "      <td>autism age vaccine 2022 am posted health our 0600 my about will its their comments us children current her affairs more who me been reading public defense new him continue</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.ageofautism.com/donate.html</th>\n",
       "      <td>hello your donation to autism age is tax now use for secure online donations scroll down for their easy to use form you can always send us a paper or electronic check as well email me at any time with ideas suggestions or gentle critiques our is you ed cause unknown the epidemic of sudden deaths in 2021 2022 health defense transcend fear a blueprint for mindful leadership in public health jr f the real bill gates big and the global war on democracy and public health health defense donate click the cover buy the book shop amazon support recent comments past current contributors connect sear...</td>\n",
       "      <td>health donate defense public hello donation autism age tax now secure online donations scroll down their easy form always send us paper electronic check well email me any time ideas</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.ageofautism.com/contact-us.html</th>\n",
       "      <td>autism age box 110546 ct 06611 ed cause unknown the epidemic of sudden deaths in 2021 2022 health defense transcend fear a blueprint for mindful leadership in public health jr f the real bill gates big and the global war on democracy and public health health defense donate click the cover buy the book shop amazon support recent comments past current contributors connect search donate contact us top</td>\n",
       "      <td>health defense public donate autism age box 110546 ct 06611 ed cause unknown epidemic sudden deaths 2021 2022 transcend fear blueprint mindful leadership jr f real bill gates big global</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.ageofautism.com/exclusives.html</th>\n",
       "      <td>editorials from the series by the and here i come you had me at an elaborate fraud series deer special report what do epidemiological studies really tell us a note from there are 16 epidemiological studies here on vaccines and autism these studies represent the most often cited papers by scientists public health officials and members of the media when trying to refute any evidence of an association between vaccinations and autism there are serious methodological limitations design flaws conflicts of interest or other problems related to each of these 16 studies these flaws have been pointe...</td>\n",
       "      <td>autism studies health these series here public epidemiological 16 vaccines officials limitations flaws study defense donate editorials come me elaborate fraud deer special report do really tell us note represent</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text  \\\n",
       "http://www.ageofautism.com/                  host a program on also available as audio on you can find all of the programming on here in this week with health defense president and programming manager and discuss the latest news on vaccines and other issues click here this week health defense president and programming manager covered the latest headlines on big and other issues including news that the senate signaled its time to move on from the pandemic with a bipartisan 6236 to end the federal governments emergency declaration on the pandemic and also discussed that is pushing the claiming that children are at high risk during the ...   \n",
       "https://www.ageofautism.com/                 host a program on also available as audio on you can find all of the programming on here in this week with health defense president and programming manager and discuss the latest news on vaccines and other issues click here this week health defense president and programming manager covered the latest headlines on big and other issues including news that the senate signaled its time to move on from the pandemic with a bipartisan 6236 to end the federal governments emergency declaration on the pandemic and also discussed that is pushing the claiming that children are at high risk during the ...   \n",
       "https://www.ageofautism.com/donate.html      hello your donation to autism age is tax now use for secure online donations scroll down for their easy to use form you can always send us a paper or electronic check as well email me at any time with ideas suggestions or gentle critiques our is you ed cause unknown the epidemic of sudden deaths in 2021 2022 health defense transcend fear a blueprint for mindful leadership in public health jr f the real bill gates big and the global war on democracy and public health health defense donate click the cover buy the book shop amazon support recent comments past current contributors connect sear...   \n",
       "https://www.ageofautism.com/contact-us.html                                                                                                                                                                                                        autism age box 110546 ct 06611 ed cause unknown the epidemic of sudden deaths in 2021 2022 health defense transcend fear a blueprint for mindful leadership in public health jr f the real bill gates big and the global war on democracy and public health health defense donate click the cover buy the book shop amazon support recent comments past current contributors connect search donate contact us top   \n",
       "https://www.ageofautism.com/exclusives.html  editorials from the series by the and here i come you had me at an elaborate fraud series deer special report what do epidemiological studies really tell us a note from there are 16 epidemiological studies here on vaccines and autism these studies represent the most often cited papers by scientists public health officials and members of the media when trying to refute any evidence of an association between vaccinations and autism there are serious methodological limitations design flaws conflicts of interest or other problems related to each of these 16 studies these flaws have been pointe...   \n",
       "\n",
       "                                                                                                                                                                                                                                                    common_words  \\\n",
       "http://www.ageofautism.com/                                                          autism age vaccine 2022 am posted health our 0600 my about will its their comments us children current her affairs more who me been reading public defense new him continue   \n",
       "https://www.ageofautism.com/                                                         autism age vaccine 2022 am posted health our 0600 my about will its their comments us children current her affairs more who me been reading public defense new him continue   \n",
       "https://www.ageofautism.com/donate.html                                    health donate defense public hello donation autism age tax now secure online donations scroll down their easy form always send us paper electronic check well email me any time ideas   \n",
       "https://www.ageofautism.com/contact-us.html                            health defense public donate autism age box 110546 ct 06611 ed cause unknown epidemic sudden deaths 2021 2022 transcend fear blueprint mindful leadership jr f real bill gates big global   \n",
       "https://www.ageofautism.com/exclusives.html  autism studies health these series here public epidemiological 16 vaccines officials limitations flaws study defense donate editorials come me elaborate fraud deer special report do really tell us note represent   \n",
       "\n",
       "                                                     label  \n",
       "http://www.ageofautism.com/                  pseudoscience  \n",
       "https://www.ageofautism.com/                 pseudoscience  \n",
       "https://www.ageofautism.com/donate.html      pseudoscience  \n",
       "https://www.ageofautism.com/contact-us.html  pseudoscience  \n",
       "https://www.ageofautism.com/exclusives.html  pseudoscience  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all = {}\n",
    "for link in d_pse:\n",
    "    text = d_pse[link][0]\n",
    "    if len(text) > max_text_len: text = text[:max_text_len]\n",
    "    common_words = ' '.join([count[0] for count in d_pse[link][1]])\n",
    "    if common_words != '' and link not in d_all:\n",
    "        d_all[link] = [text, common_words, 'pseudoscience']\n",
    "\n",
    "for link in d_sci:\n",
    "    text = d_sci[link][0]\n",
    "    if len(text) > max_text_len: text = text[:max_text_len]\n",
    "    common_words = ' '.join([count[0] for count in d_sci[link][1]])\n",
    "    if common_words != '' and link not in d_all:\n",
    "        d_all[link] = [text, common_words, 'science']\n",
    "\n",
    "df = pd.DataFrame.from_dict(d_all, orient='index', columns=['text', 'common_words', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos 36 xxwrep 4 0 v 0 g 0 l o n j 0 m 0 z 0 y xxwrep 3 0 k xxwrep 4 0 1 0 0 a 0 o 0 xxunk 0 xxunk 0 xxunk 0 ex 0 0 xxunk 0 xxunk 0 xxunk xxwrep 3 0 xxunk 0 xxunk 0 xxunk xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 c o 0 chum 0 xxunk 0 xxunk 0 xxunk 0 v 0 0 xxunk 0 xxunk 0 xxunk xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 u 0 0 xxunk 0 xxunk 0 xxunk 0 3 e s i 0 s 0 xxunk 0 xxunk 0 xxunk 0 m f y 0 0 xxunk 0 xxunk 0 xxunk xxwrep 3 0 xxunk 0 xxunk 0 xxunk xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 is 6 0 f 0 xxunk 0 xxunk 0</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos c y 08 y y 73 xxwrep 13 y nu s v 12 g ab f 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 20211 xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 xxunk xxunk 0 0 g p x 0 0 xxunk version xxunk build xxunk xxunk xxunk 0 0 b x n f k b xxwrep 3 40 xxunk u h f z at m s b w a q w 0 xxunk 0 xxunk 0 xxunk 0 0 r xxunk 0 r xxunk 0 r xxunk 0 r xxunk 0 r xxunk 0 r xxunk 0 r xxunk 0 r xxunk 0 r 170 0 r xxunk 0 r xxunk 0 00 595276 50 0 00 595276 0 0 xxunk 0 xxunk xxunk xxrep 3 6</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos in stock ready to ship d verified customer team member hi the of ever since we launched our small company i have wanted to make a snack bar that i would be happy to eat you see always been the type of person to reward myself at the end of a long day with a little treat it was a xxunk i d grab my favorite cup of tea and a treat then i d sit on the xxunk and enjoy it it was a little me moment that would help me xxunk from the day the problem sometimes i would eat a piece of chocolate other times it was another snack that would feel good in the moment and horrible later on i needed something better and why i set out to create something better i wanted a snack bar a snack bar that i could happily eat</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = TextDataLoaders.from_df(df, bs=8, text_col='text', label_col='label')\n",
    "dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.606731</td>\n",
       "      <td>0.441208</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.484572</td>\n",
       "      <td>0.402184</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395984</td>\n",
       "      <td>0.361449</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311677</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213757</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.907051</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Device 0 | NVIDIA GeForce RTX 3050 Ti Laptop GPU | Allocated: 0.7 GB | Cached: 1.9 GB\n"
     ]
    }
   ],
   "source": [
    "check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxwrep 7 0 r 365 xxwrep 9 0 r xxunk xxwrep 24 0 r 373 xxwrep 9 0 r xxunk xxwrep 9 0 r 381 xxwrep 8 0 384 xxrep 10 0 xxunk xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5 0 xxrep 5</td>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos c e 0 xxunk r 0 0 18 0 0 xxunk 0 xxunk xxunk 0 xxunk 0 xxunk 0 xxunk 0 xxunk 0 19 xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 em h t 0 0 22 0 0 384 0 384 xxunk 0 xxunk 0 xxunk 0 23 xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 a 0 0 26 0 0 xxunk 0 xxunk 2903 0 xxunk 0 xxunk 0 xxunk 0 27 0 0 m 0 xxunk 0 xxunk 0 xxunk 0 xxunk 0 0 30 0 0 384 0 384 2903 0 1 xxrep 3 7 0 xxunk 0 31 xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 s p q y o 0 0 34 0 0 387 0 387 2903 0 xxunk 0 xxunk 0 xxunk 0 35 xxwrep 3 0 xxunk 0 xxunk 0 xxunk 0 e 0</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos och p system man fr den vi i av evolution one may also study the more restricted problem of ancestry and compare a model with common ancestry of the two species with a unique origin model according to which each species is founded by one single couple and carter 2014 carter 2018 and 2019 och xxunk den hr med vi vi p den man r om r i par en man och en om och om den r i art en fr 7 xxrep 4 0 r sedan d 1 xxrep 4 0 man men fr den variation vi vi d till 5 xxrep 5 0 r hr fr xxunk ha fr 6 xxrep 3 0 till 1 xxrep 4 0 r sedan om man man r i av genetic modeling of human history part 1 comparison of common xxunk and unique origin approaches och genetic modeling of human</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos all we know next is that for no apparent reason john pulled that control rod up by about twenty inches at the end of we had the unused heart of a nuclear bomb sitting around waiting to fuck shit up scientists at national laboratory be expected to just leave it alone it was so shiny so new so full of untapped data receive notifications about new blog entries and a free puppy as long as supplies out of puppies smash this subscribe button do it copyright 2022 theme by themes fission come for the science stay for the dirty jokes daily mos the reactor daily mos the xxunk core 10 2021 0 16 2021 2 tweet support on search for i ca nt stop getting on about 2 8 5 xxwrep 3 2 5 3 3 xxwrep 3 2 3 xxwrep 4 2 5 2 2 xxwrep 3 3</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos when i recall the scientist who first attempted to explain how xxunk of rock xxunk across the planet not surprised that the reaction was all due respect fuck yourself the ground gave way under the massive amount of weight to reveal a giant underground xxunk xxunk with natural gas so they did the responsible thing and xxunk the fucking pit on fire a mud volcano has been erupting 50 swimming pools worth of mud onto the east java province of for over a decade why receive notifications about new blog entries and a free puppy as long as supplies out of puppies smash this subscribe button do it copyright 2022 theme by themes xxunk come for the science stay for the dirty jokes daily mos xxunk xxunk daily mos the fifty year gas fire daily mos the mud volcano may 21 2021 0 4 2021 2 8 2021 0</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos a xxunk xxunk into your work xxunk you of killing people and demands your bodily xxunk all for making some delicious xxunk ice cream its been hard to get people to take some common sense advice during this pandemic but hand washing was an easy one to get people on board with the first guy who said hey maybe wash your hands when doctoring was beaten to death in an insane asylum receive notifications about new blog entries and a free puppy as long as supplies out of puppies smash this subscribe button do it copyright 2022 theme by themes come for the science stay for the dirty jokes daily mos the narrative of xxunk daily mos the invention of march 7 2021 1 15 2021 0 tweet support on search for i ca nt stop getting on about 2 8 5 xxwrep 3 2 5 3 3 xxwrep</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos all we know next is that for no apparent reason john pulled that control rod up by about twenty inches in 1951 they started dumping nuclear waste into lake and all was fine for a while really why ca nt you just dump a bunch of radioactive materials into a lake but have to be pretty damn determined to get radiation poisoning from a banana receive notifications about new blog entries and a free puppy as long as supplies out of puppies smash this subscribe button do it copyright 2022 theme by themes radiation come for the science stay for the dirty jokes daily mos the reactor daily mos radioactive lake daily mos the mildly radioactive banana 10 2021 0 march 3 2021 0 2 2021 2 tweet support on search for i ca nt stop getting on about 2 8 5 xxwrep 3 2 5 3 3 xxwrep</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos as the story goes a patient named bill asked for something that could help with his sexual weakness which i think was speak for raging xxunk medicine please and thank you the juice racket is based on the biblical diet of king snake oil was wronged snake oil salesmen on the other hand every last one receive notifications about new blog entries and a free puppy as long as supplies out of puppies smash this subscribe button do it copyright 2022 theme by themes pseudoscience come for the science stay for the dirty jokes daily mos the great goat xxunk xxunk daily mos the biblical roots of daily mos the xxunk of snake oil march 21 2021 0 22 2021 1 1 2021 9 tweet support on search for i ca nt stop getting on about 2 8 5 xxwrep 3 2 5 3 3 xxwrep 3 2 3</td>\n",
       "      <td>science</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sources = ['https://infowarslife.com/',\n",
    "'https://www.bbc.com/news/',\n",
    "'https://www.dailymail.co.uk/',\n",
    "'https://www.si.edu/explore/science',\n",
    "'https://www.foxnews.com/opinion',\n",
    "'https://www.disclose.tv/',\n",
    "'https://www.snopes.com/top/',\n",
    "'https://www.theskepticsguide.org/about',\n",
    "'https://www.cdc.gov/',\n",
    "'https://www.motherjones.com/',\n",
    "'https://www.huffpost.com/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://infowarslife.com/</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.747941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.bbc.com/news/</th>\n",
       "      <td>science</td>\n",
       "      <td>0.978869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.dailymail.co.uk/</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.si.edu/explore/science</th>\n",
       "      <td>science</td>\n",
       "      <td>0.955084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.foxnews.com/opinion</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.954521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.disclose.tv/</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.698332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.snopes.com/top/</th>\n",
       "      <td>science</td>\n",
       "      <td>0.948207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.theskepticsguide.org/about</th>\n",
       "      <td>science</td>\n",
       "      <td>0.991358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.cdc.gov/</th>\n",
       "      <td>science</td>\n",
       "      <td>0.901797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.motherjones.com/</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.847322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.huffpost.com/</th>\n",
       "      <td>pseudoscience</td>\n",
       "      <td>0.692879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prediction  probability\n",
       "https://infowarslife.com/               pseudoscience     0.747941\n",
       "https://www.bbc.com/news/                     science     0.978869\n",
       "https://www.dailymail.co.uk/            pseudoscience     0.626198\n",
       "https://www.si.edu/explore/science            science     0.955084\n",
       "https://www.foxnews.com/opinion         pseudoscience     0.954521\n",
       "https://www.disclose.tv/                pseudoscience     0.698332\n",
       "https://www.snopes.com/top/                   science     0.948207\n",
       "https://www.theskepticsguide.org/about        science     0.991358\n",
       "https://www.cdc.gov/                          science     0.901797\n",
       "https://www.motherjones.com/            pseudoscience     0.847322\n",
       "https://www.huffpost.com/               pseudoscience     0.692879"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_pred = {}\n",
    "\n",
    "for source in test_sources:\n",
    "    page = get_page_all(source, k, ignore_words)\n",
    "    length = len(page.cleaned_text)\n",
    "    if  length < min_text_len:\n",
    "        print(\"ERROR:\",source,length,\"words\")\n",
    "    else:\n",
    "        common_words = ' '.join([count[0] for count in page.most_common_words])\n",
    "        text = page.cleaned_text\n",
    "        with learn.no_bar(), learn.no_logging():\n",
    "            prediction = learn.predict(text)\n",
    "        if prediction[0] == \"science\":\n",
    "            p = prediction[2][1].item()\n",
    "        else:\n",
    "            p = prediction[2][0].item()\n",
    "        d_pred[source] = [prediction[0], p]\n",
    "\n",
    "df = pd.DataFrame.from_dict(d_pred, orient='index', columns=['prediction', 'probability'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/2022.11.28 Model.pth')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.save('2022.11.28 Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = load_learner('models/2022.11.28 Model.pth', cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudometer",
   "language": "python",
   "name": "pseudometer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
